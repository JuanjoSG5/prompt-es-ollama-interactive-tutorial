{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Being Clear and Direct\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "from ollama import chat, ChatResponse, Options\n",
    "\n",
    "\n",
    "# Stores the MODEL_NAME variable from the IPython store\n",
    "MODEL_NAME = \"qwen2.5:14b\"\n",
    "%store MODEL_NAME\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    response = chat(\n",
    "        model=MODEL_NAME,\n",
    "        options=Options(\n",
    "            max_tokens=4000,\n",
    "            temperature=0.0\n",
    "        ),\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  \n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "**Ollama responds best to clear and direct instructions.**\n",
    "\n",
    "Think of Ollama like any other human that is new to the job. **Ollama has no context** on what to do aside from what you literally tell it. Just as when you instruct a human for the first time on a task, the more you explain exactly what you want in a straightforward manner to Ollama, the better and more accurate Ollama's response will be.\"\t\t\t\t\n",
    "\t\t\t\t\n",
    "When in doubt, follow the **Golden Rule of Clear Prompting**:\n",
    "- Show your prompt to a colleague or friend and have them follow the instructions themselves to see if they can produce the result you want. If they're confused, Ollama's confused.\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Let's take a task like writing poetry. (Ignore any syllable mismatch - LLMs aren't great at counting syllables yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What is and haiku? Write a haiku about robots.\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This haiku is nice enough, but users may want Ollama to go directly into the poem without the \"Here is a haiku\" preamble.\n",
    "\n",
    "How do we achieve that? We **ask for it**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What is and haiku? Write a haiku about robots. Skip the preamble; go straight into the poem.\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another example. Let's ask Ollama who's the best basketball player of all time. You can see below that while Ollama lists a few names, **it doesn't respond with a definitive \"best\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Who is the best basketball player of all time?\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we get Ollama to make up its mind and decide on a best player? Yes! Just ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Who is the best basketball player of all time? Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be? Just give me the name of the player\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 2.1 - Spanish](#exercise-21---spanish)\n",
    "- [Exercise 2.2 - One Player Only](#exercise-22---one-player-only)\n",
    "- [Exercise 2.3 - Write a Story](#exercise-23---write-a-story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1 - Spanish\n",
    "Modify the `SYSTEM_PROMPT` to make Ollama output its answer in Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt - this is the only field you should chnage\n",
    "SYSTEM_PROMPT = \"{'System':'[Replace this text]'}\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Hello Ollama, how are you?\"\n",
    "\n",
    "# Get Ollama's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return \"hola\" in text.lower()\n",
    "\n",
    "# Print Ollama's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_2_1_hint; print(exercise_2_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 - One Player Only\n",
    "\n",
    "Modify the `PROMPT` so that Ollama doesn't equivocate at all and responds with **ONLY** the name of one specific player, with **no other words or punctuation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Get Ollama's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return text == \"Michael Jordan\"\n",
    "\n",
    "# Print Ollama's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_2_2_hint; print(exercise_2_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 - Write a Story\n",
    "\n",
    "Modify the `PROMPT` so that Ollama responds with as long a response as you can muster. If your answer is **over 800 words**, Ollama's response will be graded as correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Get Ollama's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    trimmed = text.strip()\n",
    "    words = len(trimmed.split())\n",
    "    return words >= 800\n",
    "\n",
    "# Print Ollama's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_2_3_hint; print(exercise_2_3_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Ollama's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What is and haiku? Write a haiku about robots.\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What is and haiku? Write a haiku about robots. Skip the preamble; go straight into the poem.\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Who is the best basketball player of all time?\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Who is the best basketball player of all time? Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be?\"\n",
    "\n",
    "# Print Ollama's response\n",
    "print(get_completion(PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
